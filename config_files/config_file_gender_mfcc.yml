# CONFIG FILE FOR AN LID EXPERIMENT
speech_data_dir: '/data/GP_MFCC_NORM_1_13/'
speech_metadata: '/speech_cls/metadata/gp_speech_data.csv'
model_save_dir: '/speech_cls/in_progress/'
seed: 1337
language_set: 'RUS CZE' # [0] pos is P+ class, [1] pos is N- class
train_samples: 1000
eval_samples: 250
experiment_name: 'gender_LID'
#
input_signal_params:
    feature_type: 'MFCC'
    max_num_frames: 384
    num_frames: 300
    sampling_rate: 16000
    sample_segment: True
    start_index: 0
    end_index: 13
#
encoder_arch:
    encoder_model: ConvEncoder
    spectral_dim: 13
    frame_dropout: True # either frame_dropout or feature_dropout can be True
    feature_dropout: False
    signal_dropout_prob: 0.0
    num_channels:
       - 128
       - 256
       - 512
    filter_sizes:
       - 1
       - 1
       - 1
    stride_steps:
       - 1
       - 1
       - 1
    pooling_type: 'max'
#
classifier_arch:
    num_classes: 2
    input_dim: 512
    hidden_dim: 512
    num_layers: 3
    unit_dropout: False
    dropout_prob: 0.0
#
training_hyperparams:
    learning_rate: 0.001
    batch_size: 128
    num_epochs: 30
    early_stopping_criteria: 50
cuda: True
catch_keyboard_interrupt: True
reload_from_files: False
expand_filepaths_to_save_dir: True
